---
title: "Stock Market Analysis: A Stock Portfolio Predictive Model"
author: "Curran Bhatia, Anupriya Tripathi, Krti Tallam, Nick Favale, Aaron Gilbert"
date: "Friday, May 4th, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Introduction
In this projected we calculated the risk of a stock investment portfolio. The question we attempted to answer is the following: ‘How accurately would we be able to predict both gains and losses of our randomly chosen stock portfolios, given what we know from our STAT 428 methods?

We have a stock market data set that spans the years 2005 to 2017, from Kaggle. This data set contains the following predictors/variables: Date, Open, High, Low, Close, Volume, OpenInt (open interest) of each stock from NYSE, NASDAQ, and NSYE MKT. Additionally, the prices were adjusted for both dividends and splits. Last, we calculated the return by conducting a “(Close1-Close2)/Close1” for each month or year’s given return.

From this data, we randomly chose a portfolio of 80 stocks, where each stock had a data point for that month or year. Portfolios of stocks are essentially a grouping of financial assets – in this case, groups of stocks comprised of a single portfolio. We began with Random Number Generation (RNG) and Monte Carlo methods to generate returns and then proceeded to find the distribution of those generated returns. Finally, we used that distribution to predict gains and losses (that is, our returns) for future market conditions of the portfolios.

\

### Methods 
\
**Data Processing**
\
As stated earlier, our dataset contains all the stock market data from the years 2005 to 2017. Although this is a lot of good data, for us it was an indicator that some companies had been dissolved and new ones emerged. Each text file contains the following variables: Date, Open, High, Low, Close, Volume, and Open Interest of any given stock on any given day. For our analysis, we only needed the Close Price in order to calculate returns, so we removed all other variables.

We decided to start with March 1st, 2005 – April 1st, 2005. This is why we created a parser that would pick out 80 random stocks and their respective Close Prices on March 1st, 2005, subtracted by the Close Price on April 1st, 2005, and then and divided by the Close Price on March 1st, 2005 to obtain a return. Below we have a picture example of the text file of Advanced Auto Parts’ stock information (Figure 1). The parser also added the name of the company to each value, although at times, this information was challenging to obtain. 



![FIGURE 1](rawdatafile.png)

It is important to note here that it was not necessary for our analysis, so it did not affect our results or predictions. Our final data set after processing is shown below (Figure 2).


![FIGURE 2](finaldataset.png)


**Group 1 Methods: Bayesian Analysis**

        	To begin by describing our prior distribution, we conducted a literature review and found that picking a random portfolio of stocks would give us a Normal Distribution. We thought it would be best to define our prior distribution as the Normal Distribution. Initially, we planned to define our prior distribution as Normal-Inverse Gamma. Unfortunately, it complicated our model quite significantly.  Thus, we decided to keep our variance constant.
        	
We also graphed what our data would look like. This is shown below in Figure 3. This allowed us to create our likelihood distribution against the Normal Distribution as well. Another important factor in this was that we had to add a constant C value in order to adjust our values, so that they made sense as practical return values.


```{r, echo=FALSE}
library(stringr)
library(readr)
library(dplyr)
```

### Read in Data
```{r, echo=FALSE}

set.seed(222)

readInStocks = function(n, date1 = "2015") {
  # Gives n number of random stocks from the S & P 500
  # 
  # Args:
  #   n: Number of random stocks to be read
  # 
  # Returns:
  #   List of dataframes with each stock's close value for each day
  
  snp = read.csv("Stocks.csv")
  
  #nums = sample(1:500, n)
  #arr100 = snp$Symbol[nums]
  #sec100 = snp$Sector[nums]
  
   dateN = date1 %>% as.character() %>% substring(1,4) %>% as.numeric()
   print(dateN)
  
  #array = arr100
  
  
  nums = c()
  
  
  stocks_2005 = list()
  
  i = 1
  while (i <= n) {
  #for (i in 1:n) {

    num = sample(1:500, 1)
    
     while (num %in% nums) {
       num = sample(1:500, 1)
       
       if (length(nums) > n) {
         return(-1)
       }
     }
    
    arr = snp$Symbol[num]
    
    # print("num is")
    # print(num)
    # print("i is")
    # print(i)
    
    dir = c("../Stocks/", as.character(arr), ".us.txt")
    
    dir2 = str_c(dir, collapse = "")
    #print(dir2)
    if(!file.exists(dir2)) {
      next
    }
    stock = read.table(dir2, sep=",", header=TRUE)
    stock[3] <- NULL
    stock[3] <- NULL
    stock[4] <- NULL
    stock[4] <- NULL
    stock[2] <- NULL
  
    stock$name <- arr
    
    

    
    beg = stock$Date[1] %>% as.character() %>% substring(1,4) %>% as.numeric()
    end = stock$Date[length(stock$Date)] %>% as.character() %>% substring(1,4) %>% as.numeric()
    
    
    if (beg > dateN || end < dateN) {
      
      i = i-1
      
      #print("Enters here:")
      
      #nums = sample(1:500, n)
      #arr100 = snp$Symbol[nums]
      #sec100 = snp$Sector[nums]
    }
    else {
      stocks_2005[[i]] <- stock
    }
    
    
    i = i+1
  }

  return(stocks_2005)

}


#readInStocks(500) -> vals


```


### Read Difference
```{r, echo=FALSE}

closeDiffPct = function(n, firstDate, secondDate, stocks_2005) {
  # Gives difference in close values from firstDate to secondDate
  # 
  # Args:
  #   n: Number of stocks to be read that are in stocks_2005
  #   firstDate: The first Date
  #   seconDate: The second Date
  #   stocks_2005: List of stock dataframes
  # 
  # Returns:
  #   A dataframe with the differences in percentage of close values, 
  #   with the stock name next to it
  
  
  rets = numeric(n)
  names = c()
  
  
  
  for (i in 1:n) {
     stock_df = stocks_2005[[i]]
     stock_df$Date = as.character(stock_df$Date)
     firstN = which(stock_df$Date == firstDate)
     secondN = which(stock_df$Date == secondDate)
     #print(firstN)
     #print(secondN)
     
     if ((is.integer(firstN) && length(firstN) == 0) | 
         (is.integer(secondN) && length(secondN) == 0)) {
       
       names = c("", names)
       next
     }
  
     stock_close_03 <- stock_df[firstN,]$Close 
     stock_close_04 <- stock_df[secondN,]$Close
     s_2005 <- (stock_close_04-stock_close_03)/stock_close_03
     
     #print(s_2005)
     rets[i] = s_2005
     names = c(stock_df$name[1], names)
  }
  
   return2005 = data.frame(rets, names)
   return2005
   
   return(return2005)
    
}

```


### Run Code
```{r, echo=FALSE}

set.seed(679)

#Run code
 stocks = readInStocks(250)
 readValues = closeDiffPct(250, "2005-03-01", "2005-06-01", stocks)
 hist(readValues$rets)
 mean(readValues$rets)
 var(readValues$rets)

```

###Graph Data
```{r, echo=FALSE}

hist(readValues$rets)
mean(readValues$rets)
var(readValues$rets)

```


\

**Group 2 Methods: MCMC**
        	For MCMC we took a likelihood function and flooded it with data from the years 2006 to 2008 S&P 500 and then with years 2008 to 2010 S&P 500 to see the difference between “normal” stock market conditions and the stock market crash of 2008. The stock market data is only being passed through the likelihood function. For each iteration after the first, the previous year’s posterior became the prior for the next year. We multiplied the updated prior by the likelihood with the current year’s data. Our equations are show below: 

Prior distribution: $$g({\theta},{\sigma^2}) = Normal() * InverseGamma() $$
Likelihood function: $$L({\mu},{\sigma^2};x_1,...,x_n) = (2\pi{\sigma^2})^{-n/2}  exp({-1/{2\sigma^2}} \sum\limits_{j=1}^n (x_j - \mu)^2)$$
Posterior distribution: $$g(\theta,\sigma^2 | x_i) = L({\mu},{\sigma^2};x_1,...,x_n) * g({\theta},{\sigma^2})$$

### Results
\
**RESULTS FOR GROUP 1 METHODS**
\
Our results for our Group 1 Methods resulted in two graphs, shown below. The first graph is without a C-value (which we had to put in to put our values into context, as mentioned earlier). The Y-axis on this graph has very low values - therefore, it was necessary that we multiplied by C. We found the C-value by multiplying our Likelihood function by our Prior function. Taking the Mean of that resulting function became our Posterior. Then, we divided that by our C-value. This results in our second graph (also shown below). This contains our Posterior distribution after dividing by C. 


```{r, echo=FALSE}
###Prior
# g_prior = function(x = seq(-1,1,.01), theta = 0, var1 = 1, alpha = 3, beta = 1) {
#   #return(dnorm(x, theta, var1)*dgamma(x, alpha, beta))
#   return(dnorm(x)*1)
# }

```

```{r, echo=FALSE}
# x <- seq(-1,1,.01)
# hist(g_prior(x, theta, var1, alpha, beta))
# gp = g_prior(x, theta, var1, alpha, beta)
# plot(x,gp)
```

```{r, echo=FALSE}
###Creating First Likelihood Function

L = function(theta, x, n, sigma2 = 2){
  first = (2*pi*sigma2)^(-n/2)
  second = exp((-1/(2*sigma2))*sum((x - theta)^2))
  return(first*second)
}

```

```{r, echo=FALSE}
### Finding Posterior and Running Code
set.seed(679)


gprior = function (theta, mu = 0, sigma = 2) {
  return (dnorm(theta, mu, sigma))
}



n = 80

# Get return differences
stocks = readInStocks(n)
readValues = closeDiffPct(n, "2005-03-01", "2005-06-01", stocks)
rets = readValues$rets


# posterior distribution
theta = seq(-10, 8, length.out = n)
gp = gprior(theta)
Li = L(theta, rets, n)
post = Li*gp

plot(theta, post)
```
\

\
```{r, echo=FALSE}
c = L(theta, rets, n) * gprior(rnorm(n))
C = mean(c)

postC = (post/C)

plot(theta, postC)

```

**Group 2 Methods: MCMC & Bootstrap and Jackknife Results**
In our results for Group 2 Methods, we can see the graphs resulting from our Markov Chain. The first graph is from 2008-2010 and the other graph is from 2005-2008. From these graphs we are able to obtain the maxiumum of the distribution. The x-axis (theta) shows the percentage change in the stock market. The y-axis is capturing the percentage of companies that are exhibiting the theta change in returns. However, here we needed to adjust our C-value to capture that specifically for future analysis. 

After conducting MCMC, we conducted a Bootstrap and Jackknife analysis on our data.  

```{r, echo=FALSE}

#markov = function (n, dates ) {

n= 80
dates = c("2008-03-04", "2009-03-03", "2010-03-03")



  set.seed(679)


  # Get return differences
  theta = seq(-8, 8, length.out = n)
  
  
  finalPost = gprior(theta)
  
  list1 = list()
  
  for (i in 1:(length(dates)-1)) {
    
    #i = 1
    stocks = readInStocks(n)
    readValues = closeDiffPct(n, dates[i], dates[i+1], stocks)
    rets = readValues$rets
    
    Li = L(theta, rets, n)
    
    c = L(theta, rets, n) * gprior(rnorm(n))
    C = mean(c)
  
  
    finalPost = finalPost*(Li/C)
    
    list1[[i]] = rets
  
  }
  
  plot(theta, finalPost)
  
  # The theta value for the max finalPost
  maxInd = which.max(finalPost)
  theta[maxInd]
  paste("The value of theta for the max value in our final posterior distribution is : ",   theta[maxInd])

#}

```

\

Here we can see the maximum is below a theta value of 0. This makes sense as it was after the Stock Market Crash of 2008 and the market was still recovering. 


\

```{r, echo=FALSE}

#markov = function (n, dates ) {

n= 80
dates = c("2005-03-01", "2006-03-01", "2007-03-01", "2008-03-04")



  set.seed(100)


  # Get return differences
  theta = seq(-8, 8, length.out = n)
  
  
  finalPost = gprior(theta)
  
  list1 = list()
  
  for (i in 1:(length(dates)-1)) {
    
    #i = 1
    stocks = readInStocks(n)
    readValues = closeDiffPct(n, dates[i], dates[i+1], stocks)
    rets = readValues$rets
    
    Li = L(theta, rets, n)
    
    c = L(theta, rets, n) * gprior(rnorm(n))
    C = mean(c)
  
  
    finalPost = finalPost*(Li/C)
    
    list1[[i]] = rets
  
  }
  
  plot(theta, finalPost)
  
  # Theta value for the max finalPost
  maxInd = which.max(finalPost)
  theta[maxInd]
  paste("The value of theta for the max value in our final posterior distribution is : ",   theta[maxInd])

#}


```
\

Here we can see that the maximum is above a theta value of 0. This makes sense as it was before the Stock Market Crash of 2008.

\

```{r, echo=FALSE}
###Bootstrap
T = mean(rets)

B = 10000

thetahat = mean(rets)

thetahatboot = numeric(B)

for(b in 1:B) {
 
   xb = sample(rets, 50, replace = TRUE)
  
   thetahatboot[b] = mean(xb)
}

sethetahat = sd(thetahatboot)

sethetahat

mean(thetahatboot)

T

```

\
In our bootstrap analysis, we found that the standard error was small (0.07) which is one factor for indicating that our model is strong.
\

```{r, echo=FALSE}
###Jackknife
library("bootstrap")
# initialize
#data(law, package = "bootstrap")

n <- length(rets)

y <- rets

B <- 2000

theta.b <- numeric(B)
# set up storage for the sampled indices

indices <- matrix(0, nrow = B, ncol = n)
# jackknife-after-bootstrap step 1: run the bootstrap

for (b in 1:B) {

i <- sample(1:n, size = n, replace = TRUE)

y <- rets[i]

theta.b[b] <- mean(y)
#save the indices for the jackknife

indices[b,] <- i

}


se.jack <- numeric(n)

for (i in 1:n) {
# in i-th replicate omit all samples with x[i]

  keep <- (1:B)[apply(indices, MARGIN = 1,

                      FUN = function(k) {!any(k == i)})]

  se.jack[i] <- sd(theta.b[keep])
}

sumsq = sum((se.jack-mean(se.jack))^2)

sejack = sqrt((n-1)/n)*sqrt(sumsq)

print(sqrt(sejack))

print(mean(theta.b))

print(sd(theta.b))
# print(sqrt((n-1) * mean((se.jack - mean(se.jack))^2)))

print(mean(rets))

print(sd(rets))

```

\
For our jackknife analysis, we got a standard deviation of (0.058) while for returns (our original data) we got a standard deviation of 0.52. This can be attributed to (ASK NICK).
\

###Conclusion
We verified that through our randomly selected portfolio of 80 stocks from the S&P 500 that it is reasonable to accurately estimate year on year returns for the S&P 500 based on a normal distribution. 

However, we need to keep in mind that we needed to adjust our Markov Chain in order to readjust our C-value. The reason we did this was once again, to normalize our values in order to accurately analyze our distributions correctly. 

Some future routes we can take **WHY DID OUR DATA BREAK - CURRAN AND AARON**




### Appendices
\

```{r echo=TRUE, include=FALSE}

library(stringr)
library(readr)
library(dplyr)
```

### Read in Data
```{r echo=TRUE, include=FALSE}


set.seed(222)

readInStocks = function(n, date1 = "2015") {
  # Gives n number of random stocks from the S & P 500
  # 
  # Args:
  #   n: Number of random stocks to be read
  # 
  # Returns:
  #   List of dataframes with each stock's close value for each day
  
  snp = read.csv("Stocks.csv")
  
  #nums = sample(1:500, n)
  #arr100 = snp$Symbol[nums]
  #sec100 = snp$Sector[nums]
  
   dateN = date1 %>% as.character() %>% substring(1,4) %>% as.numeric()
   print(dateN)
  
  #array = arr100
  
  
  nums = c()
  
  
  stocks_2005 = list()
  
  i = 1
  while (i <= n) {
  #for (i in 1:n) {

    num = sample(1:500, 1)
    
     while (num %in% nums) {
       num = sample(1:500, 1)
       
       if (length(nums) > n) {
         return(-1)
       }
     }
    
    arr = snp$Symbol[num]
    
    # print("num is")
    # print(num)
    # print("i is")
    # print(i)
    
    dir = c("../Stocks/", as.character(arr), ".us.txt")
    
    dir2 = str_c(dir, collapse = "")
    #print(dir2)
    if(!file.exists(dir2)) {
      next
    }
    stock = read.table(dir2, sep=",", header=TRUE)
    stock[3] <- NULL
    stock[3] <- NULL
    stock[4] <- NULL
    stock[4] <- NULL
    stock[2] <- NULL
  
    stock$name <- arr
    
    

    
    beg = stock$Date[1] %>% as.character() %>% substring(1,4) %>% as.numeric()
    end = stock$Date[length(stock$Date)] %>% as.character() %>% substring(1,4) %>% as.numeric()
    
    
    if (beg > dateN || end < dateN) {
      
      i = i-1
      
      #print("Enters here:")
      
      #nums = sample(1:500, n)
      #arr100 = snp$Symbol[nums]
      #sec100 = snp$Sector[nums]
    }
    else {
      stocks_2005[[i]] <- stock
    }
    
    
    i = i+1
  }

  return(stocks_2005)

}


#readInStocks(500) -> vals


```


### Read Difference
```{r echo=TRUE, include=FALSE}


closeDiffPct = function(n, firstDate, secondDate, stocks_2005) {
  # Gives difference in close values from firstDate to secondDate
  # 
  # Args:
  #   n: Number of stocks to be read that are in stocks_2005
  #   firstDate: The first Date
  #   seconDate: The second Date
  #   stocks_2005: List of stock dataframes
  # 
  # Returns:
  #   A dataframe with the differences in percentage of close values, 
  #   with the stock name next to it
  
  
  rets = numeric(n)
  names = c()
  
  
  
  for (i in 1:n) {
     stock_df = stocks_2005[[i]]
     stock_df$Date = as.character(stock_df$Date)
     firstN = which(stock_df$Date == firstDate)
     secondN = which(stock_df$Date == secondDate)
     #print(firstN)
     #print(secondN)
     
     if ((is.integer(firstN) && length(firstN) == 0) | 
         (is.integer(secondN) && length(secondN) == 0)) {
       
       names = c("", names)
       next
     }
  
     stock_close_03 <- stock_df[firstN,]$Close 
     stock_close_04 <- stock_df[secondN,]$Close
     s_2005 <- (stock_close_04-stock_close_03)/stock_close_03
     
     #print(s_2005)
     rets[i] = s_2005
     names = c(stock_df$name[1], names)
  }
  
   return2005 = data.frame(rets, names)
   return2005
   
   return(return2005)
    
}

```


### Run Code
```{r echo=TRUE, include=FALSE}


#set.seed(679)

#Run code
 #stocks = readInStocks(250)
 #readValues = closeDiffPct(250, "2005-03-01", "2005-06-01", stocks)
 #hist(readValues$rets)
 #mean(readValues$rets)
 #var(readValues$rets)

```

Prior distribution: $$g({\theta},{\sigma^2}) = Normal() * InverseGamma() $$
Likelihood function: $$L({\mu},{\sigma^2};x_1,...,x_n) = (2\pi{\sigma^2})^{-n/2}  exp({-1/{2\sigma^2}} \sum\limits_{j=1}^n (x_j - \mu)^2)$$
Posterior distribution: $$g(\theta,\sigma^2 | x_i) = L({\mu},{\sigma^2};x_1,...,x_n) * g({\theta},{\sigma^2})$$



###Graph Data
```{r echo=TRUE, include=FALSE}


# hist(readValues$rets)
# mean(readValues$rets)
# var(readValues$rets)

```

###Prior
```{r echo=TRUE, include=FALSE}


# g_prior = function(x = seq(-1,1,.01), theta = 0, var1 = 1, alpha = 3, beta = 1) {
#   #return(dnorm(x, theta, var1)*dgamma(x, alpha, beta))
#   return(dnorm(x)*1)
# }

```

```{r echo=TRUE, include=FALSE}

# x <- seq(-1,1,.01)
# hist(g_prior(x, theta, var1, alpha, beta))
# gp = g_prior(x, theta, var1, alpha, beta)
# plot(x,gp)
```



###Creating First Likelihood Function
```{r echo=TRUE, include=FALSE}

L = function(theta, x, n, sigma2 = 2){
  first = (2*pi*sigma2)^(-n/2)
  second = exp((-1/(2*sigma2))*sum((x - theta)^2))
  return(first*second)
}

```


### Finding Posterior and Running Code
```{r echo=TRUE, include=FALSE}

set.seed(679)


gprior = function (theta, mu = 0, sigma = 2) {
  return (dnorm(theta, mu, sigma))
}



n = 80

# Get return differences
stocks = readInStocks(n)
readValues = closeDiffPct(n, "2005-03-01", "2005-06-01", stocks)
rets = readValues$rets


# posterior distribution
theta = seq(-10, 8, length.out = n)
gp = gprior(theta)
Li = L(theta, rets, n)
post = Li*gp

plot(theta, post)


c = L(theta, rets, n) * gprior(rnorm(n))
C = mean(c)

postC = (post/C)

plot(theta, postC)

```


### Markov Chain
```{r echo=TRUE, include=FALSE}


#markov = function (n, dates ) {

n= 80
dates = c("2008-03-04", "2009-03-03", "2010-03-03")



  set.seed(679)


  # Get return differences
  theta = seq(-8, 8, length.out = n)
  
  
  finalPost = gprior(theta)
  
  list1 = list()
  
  for (i in 1:(length(dates)-1)) {
    
    #i = 1
    stocks = readInStocks(n)
    readValues = closeDiffPct(n, dates[i], dates[i+1], stocks)
    rets = readValues$rets
    
    Li = L(theta, rets, n)
    
    c = L(theta, rets, n) * gprior(rnorm(n))
    C = mean(c)
  
  
    finalPost = finalPost*(Li/C)
    
    list1[[i]] = rets
  
  }
  
  plot(theta, finalPost)
  
  # The theta value for the max finalPost
  maxInd = which.max(finalPost)
  theta[maxInd]
  paste("The value of theta for the max value in our final posterior distribution is : ",   theta[maxInd])

#}

```

```{r echo=TRUE, include=FALSE}


#markov = function (n, dates ) {

n= 80
dates = c("2005-03-01", "2006-03-01", "2007-03-01", "2008-03-04")



  set.seed(100)


  # Get return differences
  theta = seq(-8, 8, length.out = n)
  
  
  finalPost = gprior(theta)
  
  list1 = list()
  
  for (i in 1:(length(dates)-1)) {
    
    #i = 1
    stocks = readInStocks(n)
    readValues = closeDiffPct(n, dates[i], dates[i+1], stocks)
    rets = readValues$rets
    
    Li = L(theta, rets, n)
    
    c = L(theta, rets, n) * gprior(rnorm(n))
    C = mean(c)
  
  
    finalPost = finalPost*(Li/C)
    
    list1[[i]] = rets
  
  }
  
  plot(theta, finalPost)
  
  # Theta value for the max finalPost
  maxInd = which.max(finalPost)
  theta[maxInd]
  paste("The value of theta for the max value in our final posterior distribution is : ",   theta[maxInd])

#}


```






###Bootstrap
```{r echo=TRUE, include=FALSE}


T = mean(rets)

B = 10000

thetahat = mean(rets)

thetahatboot = numeric(B)

for(b in 1:B) {
 
   xb = sample(rets, 50, replace = TRUE)
  
   thetahatboot[b] = mean(xb)
}

sethetahat = sd(thetahatboot)

sethetahat

mean(thetahatboot)

T

```



###Jackknife
```{r echo=TRUE, include=FALSE}


library("bootstrap")
# initialize
#data(law, package = "bootstrap")

n <- length(rets)

y <- rets

B <- 2000

theta.b <- numeric(B)
# set up storage for the sampled indices

indices <- matrix(0, nrow = B, ncol = n)
# jackknife-after-bootstrap step 1: run the bootstrap

for (b in 1:B) {

i <- sample(1:n, size = n, replace = TRUE)

y <- rets[i]

theta.b[b] <- mean(y)
#save the indices for the jackknife

indices[b,] <- i

}


se.jack <- numeric(n)

for (i in 1:n) {
# in i-th replicate omit all samples with x[i]

  keep <- (1:B)[apply(indices, MARGIN = 1,

                      FUN = function(k) {!any(k == i)})]

  se.jack[i] <- sd(theta.b[keep])
}

sumsq = sum((se.jack-mean(se.jack))^2)

sejack = sqrt((n-1)/n)*sqrt(sumsq)

print(sqrt(sejack))

print(mean(theta.b))

print(sd(theta.b))
# print(sqrt((n-1) * mean((se.jack - mean(se.jack))^2)))

print(mean(rets))

print(sd(rets))

```

